{
  "hash": "f7add21b9bfb5feb8e4afcf41a98490a",
  "result": {
    "markdown": "---\ntitle: \"Estimating the Unique Values in a Set\"\nauthor: \"Vitaly Druker\"\ndate: \"2016-12-01\"\ncategories: [R, combinatorics, simulation]\n---\n\n\n\n### Motivation \nA friend asked me to help him figure out some probabilities related to microwell plates that he was analyzing in his lab.\nA [90 well plate](https://en.wikipedia.org/wiki/Microtiter_plate) was filled from a mixed sample of an unknown number of unique particles. Let's say there are a total of _s_ total particles in the original sample. My friend said that he observed 88 unique particles in the 90 well plate. His question was simple: can we estimate the number of unique particles (_s_) in the original bag?\n\nWe can write this a little more succinctly: \n\n> If we draw 90 items from a set (with replacement) and we see 88 unique items, what is the probability that the set has _s_ unique members? Can we calculate $P(s|x,t)$ where _x_ is the unique items observed out of a draw size _t_.\n\n\n### Simulation\nLet's get an idea of what the solution should look like by running a simulation. The example below will test various _S_ values between 90 and 30,000 with 1,000 simulations per _S_ size. For each size, we try to find the probability of drawing _exactly_ 88 unique samples. \n\n\n\n```{.r .cell-code}\nsimXgS <- function(s, t = 90, x = 88, num_samples = 1000) {\n  # Calculates the probability of drawing x unique samples\n  out <- c()\n  for (i in 1:num_samples) {\n    samp <- sample(1:s, size = t, replace = T) # draw 90\n    v <- (length(unique(samp)) == x)\n    out <- c(out, v)\n  }\n  mean(out)\n}\n\nset.seed(1)\nbag <- seq(from = 90, to = 20000, by = 50) # S Values\n\nfull_out <- sapply(bag,\n                   simXgS,\n                   t = 90,\n                   x = 88,\n                   num_samples = 1000)\n\np_full_out <- full_out / sum(full_out)\n\ndf_sim <-\n  data.frame(S = bag, pdf = p_full_out)\nbest_S <- df_sim$S[which.max(df_sim$pdf)]\n```\n\n\nSome of you may have made the correct observation that we are actually calculating $P(x|s,t)$. That is what `full_out` represents. However, as you will see below, we can use Bayes Rule to show that this is valid when we scale by the sum of all values (`p_full_out`). In other words: \n$$ P(s|x,t) = \\frac{P(x|s,t)}{\\sum_s{P(x|s,t)}}$$\n\nThe graph below shows the scaled probability of the true number of unique values in the original sample. The labeled vertical line shows the best guess for the value of _s_ based off the simulations.\n\n\n![](index_files/figure-html/graph_sim-1.png){width=672}\n\n\n\n\nWe can even run the simulation multiple times (code not shown) to get a better estimate of _s_. After 100 simulations, the best _s_ is **2006** (95% CI [**1968**, **2045**]). The plot below shows the distribution of these values.\n\n\n![](index_files/figure-html/sS_hist-1.png){width=672}\n\n\n### Analytic Solution  \n\nNow let's see if we can calculate $P(s|x,t)$ without using simulation. We can start with Bayes Rule:\n$$ P(s|x,t) = \\frac{P(x|s,t)P(s|t)}{P(x|t)}$$\nWe can  calculate the formula for $P(x|s,t)$ by using combinatorics:\n$$ P(x|s,t) \\propto \\frac{s!}{s^{x}(s-x)!}*\\frac{\\binom{t-1}{t-x}}{s^{t-x}}$$\n\nNote the 'proportional' sign that's used instead of an 'equal' sign. I will show why this is not important shortly. Let's look at $P(s|t)$. First we notice that _s_ is entirely independent of _t_. (I can use a plate of any size for testing, it probably relates to the capabilities of the device measuring the wells, not _s_). Additionally, we can  give _s_ a uniform distribution; It's equally likely to be any number in the range we are testing.\n\n$$ P(s|t) = P(s) = \\frac{1}{q}$$\n\nWhere _q_ equals the whole range we are testing _s_ over (`length(bag)`).\n\nLastly we turn to $P(x|t)$, which is the marginal distribution of _x_ over all of the possible values of _s_. \n\n$$\\begin{aligned}P(x|t) &=  \\int_s{P(x|s,t)P(s|t)ds} \\\\\\\\\n& = \\int_s{P(x|s,t)\\frac{1}{q}ds} \\\\\\\\\n& = \\frac{1}{q}\\int_s{P(x|s,t)ds} \\\\\\\\\\\n& = \\frac{1}{q}\\sum_s{P(x|s,t)}\n\\end{aligned}\n$$\nNow let's put it all together:\n$$\\begin{aligned}\nP(s|x,t) &= \\frac{P(x|s,t)P(s|t)}{P(x|t)} \\\\\\\\\n\\\\\n&= \\frac{P(x|s,t)\\frac{1}{q}}{\\frac{1}{q}\\sum_s{P(x|s,t)}}\\\\\\\\\n\\\\\n& = \\frac{P(x|s,t)}{\\sum_s{P(x|s,t)}}\n\\end{aligned}\n$$\nThis result accomplished two goals:\n\n1. It justifies dividing by the sum of all the probabilities (as we did in the first section). \n\n2. It means that our analytic solution to $P(x|s,t)$ can be proportional to the true value (as long as it does not contain an _s_). Any proportions like that will act as the $\\frac{1}{q}$ did and get cancelled out. \n\nBelow I've written a function for calculating $P(x|s,t)$ where _t_ = `plates` and _x_ = `observed_unique`. \n\n\n\n```{.r .cell-code}\nprobXgS <- function(s,\n                    t = 90,\n                    x = 88) {\n  m_vs <- t - x\n  prod(s:(s - (x - 1)) / s) *\n    choose(x + m_vs - 1, m_vs) *\n    1 / s ^ m_vs\n}\n\ncomp_out <- sapply(bag, probXgS, x = 88, t = 90)\np_comp_out <- comp_out / sum(comp_out)\n\ndf_sim$calc_pdf <- p_comp_out\nbest_S_calc <-\n  df_sim$S[which.max(df_sim$calc_pdf)]\n```\n\n\nThe graphs show that the analytic solution (red) correctly approximates the probability distribution of the simulation. The most likely value for $s$ is also shown.\n\n\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n\n\nLastly, we can look at the performance to the simulation more directly by plotting the residuals:\n\n\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n\nThe residuals are fairly constant for all calculated values. There is naturally bunching near 0 because of chosen values for _s_.\n\n### Conclusion\n\nThis post shows my method for solving these sort of problems. Doing simulations like I showed in the first part really makes the problem, and statistics, come alive. Once I have a good understanding of the actual problem, I like to think of an analytic solution that can be generalized to other forms of the same problem. Below I show some example where the number of plates and the unique observations differs from those of the original problem. You can also fine all the code for this blog post on [my GitHub](https://github.com/vitallish/westendstats/tree/master/2016/12).\n\n\n![](index_files/figure-html/sim_3-1.png){width=672}\n\n![](index_files/figure-html/sim4-1.png){width=672}\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}